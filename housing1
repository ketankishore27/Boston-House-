# ------------------------> Importing the required Libraries -----------------------------------

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from copy import deepcopy

# ------------------------> Getting the data ---------------------------------------------------

dataset_train = pd.read_csv('train.csv').iloc[:, 1:-1]
dataset_test = pd.read_csv('test.csv').iloc[:, 1:]
#dataset_test['SalePrice'] = 0

# ------------------------> Filling numerical spaces with mean (training set)--------------------
col_num = []
for i in dataset_train.columns:
    if (type(dataset_train[i][1]) == np.int64) or (type(dataset_train[i][1]) == np.float64):
        col_num.append(i)
        
col_cat = []
for i in dataset_train.columns:
    if (type(dataset_train[i][1]) != np.int64) and (type(dataset_train[i][1]) != np.float64):
        col_cat.append(i)

from sklearn.preprocessing import Imputer

imputer = Imputer(missing_values = np.nan, strategy = 'mean')

dataset_train_num = dataset_train[col_num]
dataset_train_num = pd.DataFrame(imputer.fit_transform(dataset_train_num[[i for i in dataset_train_num.columns 
                                                         if (type(dataset_train_num[i][1]) == np.int64) or 
                                                         (type(dataset_train_num[i][1]) == np.float64)]]), columns = col_num)    

dataset_train_cat = dataset_train[col_cat] 

dataset_train = pd.concat([dataset_train_num, dataset_train_cat], axis = 1)   

# ------------------------> Filling numerical spaces with mean (test set)--------------------
col_num = []
for i in dataset_test.columns:
    if (type(dataset_test[i][1]) == np.int64) or (type(dataset_test[i][1]) == np.float64):
        col_num.append(i)
        
col_cat = []
for i in dataset_test.columns:
    if (type(dataset_test[i][1]) != np.int64) and (type(dataset_test[i][1]) != np.float64):
        col_cat.append(i)

from sklearn.preprocessing import Imputer

imputer = Imputer(missing_values = np.nan, strategy = 'mean')

dataset_test_num = dataset_test[col_num]
dataset_test_num = pd.DataFrame(imputer.fit_transform(dataset_test_num[[i for i in dataset_test_num.columns 
                                                         if (type(dataset_test_num[i][1]) == np.int64) or 
                                                         (type(dataset_test_num[i][1]) == np.float64)]]), columns = col_num)    

dataset_test_cat = dataset_test[col_cat] 

dataset_test = pd.concat([dataset_test_num, dataset_test_cat], axis = 1)   

# --------------------> concatening training and test set ------------------------------------

dataset = pd.concat([dataset_train, dataset_test], axis = 0, join = 'inner')
#dataset = dataset.drop('SalePrice', axis = 1, inplace = True)

# --------------------> Filling Null values with the mode ------------------------------------

dataset.fillna(dataset.mode().iloc[0], inplace = True)

# --------------------> Getting Dummy Variables ----------------------------------------------

dataset = pd.get_dummies(dataset, drop_first=True)
dataset_backup = deepcopy(dataset)
dataset = deepcopy(dataset_backup)
dataset_scaled = deepcopy(dataset)

# --------------------> Spliiting the dataset into training and test -------------------------

training_set = dataset.iloc[:1460, :]
test_set = dataset.iloc[1460:, :]

# --------------------> Using Random Forest --------------------------------------------------
X_train = training_set
y_train = pd.read_csv('train.csv').iloc[:, -1]

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 10, n_jobs = -1, random_state = 0)
regressor.fit(X_train, y_train)

from sklearn.model_selection import cross_val_score
score = cross_val_score(regressor, X = X_train, y = y_train, cv = 10)
print(score.mean())
# --------------------> Predicting the test Results ---

X_test = test_set
y_pred = regressor.predict(X_test)

# --------------------> trying to perform Lasso regression -----------------------------------

from sklearn.linear_model import Lasso
lasso = Lasso(alpha = 100, random_state = 0)
lasso.fit(X_train, y_train)

from sklearn.model_selection import cross_val_score
score = cross_val_score(lasso, X = X_train, y = y_train, cv = 10)
print(score.mean())

from sklearn.model_selection import GridSearchCV
parameter = [{'alpha' : [i for i in range(10,500,10)]}]
grid_search = GridSearchCV(estimator = lasso, param_grid = parameter, cv = 100)
grid_search.fit(X_train, y_train)

# --------------------> Predicting the test Results ---

y_pred = grid_search.predict(X_test)

# --------------------> Predicting results after Grid Search -----

score = cross_val_score(lasso, X = X_train, y = y_train, cv = 10)
print(score.mean())

# --------------------> Trying SVM Regressor -------------------------------------

from sklearn.svm import SVR
sregressor = SVR(kernel = 'linear', gamma = 'auto', C = 100)
sregressor.fit(X_train, y_train)

score = cross_val_score(sregressor, X = X_train, y = y_train, cv = 10)
print(score.mean())

# SVR gives very bad results, so discarding this model

# --------------------> Checking the important features --------------------------

important = regressor.feature_importances_

# As I can see there are feature which just acts as noise, Thus we need to remove those variables and then check the results

j = 0
features = []
for i in dataset.columns:
  features.append([i, important[j]])
  j = j + 1
  
features.sort(key = lambda x: x[1], reverse = True)

# ---------------------> Trying out Extra Tree Regreesor -----------------------

from sklearn.ensemble import ExtraTreesRegressor
eregressor = ExtraTreesRegressor()
eregressor.fit(X_train, y_train)

important_1 = sorted(eregressor.feature_importances_, reverse = True)

j = 0
features_1 = []
for i in dataset.columns:
  features_1.append([i, important_1[j]])
  j = j + 1
  
features.sort(key = lambda x: x[1], reverse = True)

# ---------------------> Trying Gradient Boosting Algo ---------------------------

from sklearn.ensemble import GradientBoostingRegressor
gregressor = GradientBoostingRegressor(learning_rate = 0.005, n_estimators = 10000)
gregressor.fit(X_train, y_train) 


score = cross_val_score(gregressor, X = X_train, y = y_train, cv = 10)
print(score.mean())

y_pred = gregressor.predict(X_test)

# ----------------------> Trying XGBoost Algo ------------------------------------

from xgboost import XGBRegressor
xregressor = XGBRegressor(learning_rate = 0.01, n_estimators = 1000, reg_lambda = 5, verbose = 10, n_jobs = -1)
xregressor.fit(X_train, y_train)

score = cross_val_score(xregressor, X = X_train, y = y_train, cv = 10)
print(score.mean())

y_pred = xregressor.predict(X_test)

parameter = [{'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1], 
              'n_estimators' : [i for i in range(100, 1000, 100)],
              'reg_lambda' : [i for i in range(1, 10, 1)],
              'n_jobs' : [-1]}]

from sklearn.model_selection import GridSearchCV
grid_search = GridSearchCV(estimator = xregressor, param_grid = parameter, scoring = 'neg_mean_squared_error', verbose = 10, cv = 100)
grid_search.fit(X_train, y_train)

score = cross_val_score(xregressor, X = X_train, y = y_train, cv = 10)
print(score.mean())

y_pred = grid_search.predict(X_test)

# ----------------------> Trying Stochastic Gradient Descent Algorithm -----------

from sklearn.linear_model import SGDRegressor
sgregressor = SGDRegressor(alpha = 100, max_iter = 1000)
sgregressor.fit(X_train, y_train)

score = cross_val_score(sgregressor, X = X_train, y = y_train, cv = 10)
print(score.mean())

# ----------------------> Trying Adaboost Regressor -------------------------------

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor
aregressor = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(max_depth = 3), 
                               n_estimators = 1000, learning_rate = 0.01, loss = 'linear')
aregressor.fit(X_train, y_train)


score = cross_val_score(aregressor, X = X_train, y = y_train, cv = 10)
print(score.mean())

# ----------------------> Trying Artificial Neural Networks -----------------------

from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
sc_y = StandardScaler()
X_train1 = sc_x.fit_transform(X_train)
X_test1 = sc_x.transform(X_test)

import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()

classifier.add(Dense(input_dim = 245, init = 'uniform', output_dim = 245))

classifier.add(Dense(input_dim = 245, init = 'uniform', output_dim = 245))

classifier.add(Dense(input_dim = 245, init = 'uniform', output_dim = 245))

classifier.add(Dense(input_dim = 245, init = 'uniform', output_dim = 245))

classifier.add(Dense(input_dim = 245, init = 'uniform', output_dim = 245))

classifier.add(Dense(input_dim = 245, init = 'uniform', output_dim = 1))

classifier.compile(loss = 'mean_squared_error', optimizer = 'adam')

classifier.fit(X_train1, y_train, batch_size = 10, nb_epoch = 100)

y_pred = classifier.predict(X_test1)
